# DRL Trading Base

Base de proyecto en **Python** para trading algor√≠tmico preparado para **Deep Reinforcement Learning (DRL)**.

## Estructura

```
.
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îî‚îÄ‚îÄ default.yaml
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ build_universe.py
‚îÇ   ‚îî‚îÄ‚îÄ download_history.py
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ backtest/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ simulator.py
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ccxt_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ env/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trading_env.py
‚îÇ   ‚îú‚îÄ‚îÄ policies/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deterministic.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stochastic.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ value_based.py
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_drl.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ config.py
‚îÇ       ‚îú‚îÄ‚îÄ data_io.py
‚îÇ       ‚îú‚îÄ‚îÄ logging.py
‚îÇ       ‚îú‚îÄ‚îÄ orderbook.py
‚îÇ       ‚îî‚îÄ‚îÄ risk.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_data_loader_smoke.py
‚îÇ   ‚îú‚îÄ‚îÄ test_env_smoke.py
‚îÇ   ‚îî‚îÄ‚îÄ test_policy_router.py
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ pyproject.toml
```

## Instalaci√≥n

```bash
python -m venv .venv && source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install -U pip
pip install -e .
```

> **Opcional**: para usar PPO con *stable-baselines3* necesitas `torch`. En CPU basta:
```bash
pip install "torch>=2.2" "stable-baselines3>=2.3.2"
```

## Configuraci√≥n

Copia `.env.example` a `.env` y ajusta tus claves si vas a descargar datos:
```bash
cp .env.example .env
```

Edita `configs/default.yaml` para s√≠mbolos, fees, slippage, hiperpar√°metros y pesos de *reward*.

## Descarga de datos

```bash
python scripts/download_history.py --exchange binance --symbols BTC/USDT ETH/USDT --timeframe 1m --since "2024-01-01"
```

Los datos se guardan en `data/raw/{exchange}/{symbol}/{timeframe}.parquet`.

## Construir universo de s√≠mbolos l√≠quidos

```bash
python scripts/build_universe.py --exchange binance --quote USDT --min-vol-usd 1000000
```

Salida: `data/universe/liquid_universe.csv`.

## Entrenamiento (DRL)

```bash
python -m src.training.train_drl --config configs/default.yaml --algo ppo --timesteps 20000
```

Si no tienes `stable-baselines3`, el script usa una implementaci√≥n m√≠nima de DQN incluida.

## Backtest y evaluaci√≥n

```bash
python -m src.backtest.evaluate --config configs/default.yaml --policy deterministic
```

Resultados en `reports/` + m√©tricas en consola.

## Experimento completo

```bash
python scripts/run_experiment.py --config configs/default.yaml --seed 1 --algo dqn --timesteps 1000 --data-mode price_only
```

Descarga datos si faltan, entrena y ejecuta un backtest con reporte en `reports/{exp_id}/`.

## Tests (smoke)

```bash
pytest -q
```

## Troubleshooting: rate limits/timeouts

- **Descarga lenta o errores `RateLimitExceeded`**: incrementa `--rate-limit` y `--retries`.

```bash
python scripts/download_history.py --exchange binance --symbols BTC/USDT --timeframe 1m --rate-limit 2 --retries 10
```

- **`RequestTimeout` en el exchange**: reintenta tras unos segundos; `ccxt` aplica *backoff* exponencial.

## Notas

- El *env* sigue la API Gymnasium (cae a Gym si no est√° disponible).
- La observaci√≥n incluye precio, volatilidad, drawdown local, se√±al de ‚Äúmurallas‚Äù (placeholder), estado de posici√≥n y trailing.
- Acciones discretas: 0=hold, 1=open/long, 2=close. Hay *hooks* para acciones continuas.
- *Reward* modular con *heads* configurables: PnL, turnover, drawdown y volatilidad.
- *Experience buffer* y *logging* en JSONL.

¬°A iterar sin miedo y con *stop-loss*! üí°

## UI de Configuraci√≥n (Streamlit)

Instala dependencias y lanza la interfaz:
```bash
pip install -e .  # asegura que streamlit est√© instalado por pyproject
python scripts/run_ui.py
# o directamente:
streamlit run src/ui/app.py
```

La UI permite:
- Editar y guardar `configs/default.yaml`
- Descargar hist√≥rico (ccxt) y simular 1s desde 1m si no est√° disponible
- Lanzar entrenamiento (PPO/DQN) y ver la salida
- Evaluar/backtestear con una pol√≠tica
